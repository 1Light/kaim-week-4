{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 20:32:24,716 - INFO - Starting model building process...\n",
      "2025-01-10 20:32:24,720 - INFO - Loading data from /mnt/c/Users/Nas/Contacts/Desktop/AIM/kaim-week-4/kaim-week-4/notebooks/../cleaned_data/primary_data.csv...\n",
      "2025-01-10 20:32:33,613 - INFO - Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, base_dir, data_filename=\"primary_data.csv\"):\n",
    "        \"\"\"\n",
    "        Initializes the ModelBuilder object with paths for the primary data.\n",
    "        \n",
    "        :param base_dir: The base directory where the script is located.\n",
    "        :param data_filename: The name of the primary data file.\n",
    "        \"\"\"\n",
    "        self.base_dir = os.path.abspath(base_dir)\n",
    "        self.data_folder = os.path.join(self.base_dir, \"../cleaned_data\")  # Define cleaned data folder\n",
    "        self.data_file = os.path.join(self.data_folder, data_filename)  # Path to primary_data.csv\n",
    "        self.df = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\" Load the primary data using the defined path. \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Loading data from {self.data_file}...\")\n",
    "            self.df = pd.read_csv(self.data_file)\n",
    "            logger.info(\"Data loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {e}\")\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        \"\"\" Preprocess data by handling missing values and encoding categorical features if any. \"\"\"\n",
    "        if self.df is not None:\n",
    "            # Drop rows with missing target values (Sales)\n",
    "            self.df = self.df.dropna(subset=[\"Sales\"])\n",
    "\n",
    "            # Drop non-numeric or unnecessary columns\n",
    "            self.df = self.df.drop(columns=[\"Date\", \"Store\"])  # Drop Date and Store as an example\n",
    "\n",
    "            # Handle missing values (for simplicity, we'll fill missing numerical values with the mean)\n",
    "            self.df.fillna(self.df.mean(), inplace=True)\n",
    "\n",
    "            # Assume 'Sales' is the target column\n",
    "            self.X = self.df.drop(columns=[\"Sales\"])\n",
    "            self.y = self.df[\"Sales\"]\n",
    "            \n",
    "            logger.info(\"Data preprocessing completed!\")\n",
    "    \n",
    "    def build_pipeline(self):\n",
    "        \"\"\" Build a pipeline for the regression model. \"\"\"\n",
    "        # Define the steps in the pipeline\n",
    "        steps = [\n",
    "            ('scaler', StandardScaler()),  # Standardize features\n",
    "            ('model', RandomForestRegressor(n_estimators=100, random_state=42))  # Random Forest Regressor\n",
    "        ]\n",
    "        \n",
    "        # Create the pipeline\n",
    "        pipeline = Pipeline(steps)\n",
    "        \n",
    "        return pipeline\n",
    "    \n",
    "    def train_and_evaluate(self):\n",
    "        \"\"\" Train the model using the pipeline and evaluate performance. \"\"\"\n",
    "        if self.X is not None and self.y is not None:\n",
    "            # Split the data into training and testing sets\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # Build the pipeline\n",
    "            pipeline = self.build_pipeline()\n",
    "            \n",
    "            # Train the model\n",
    "            logger.info(\"Training the model...\")\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            \n",
    "            # Calculate performance (mean squared error)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            logger.info(f\"Model performance (MSE): {mse:.4f}\")\n",
    "        else:\n",
    "            logger.error(\"Data is not preprocessed properly.\")\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\" Run the entire process of loading, preprocessing, training, and evaluation. \"\"\"\n",
    "        logger.info(\"Starting model building process...\")\n",
    "        \n",
    "        self.load_data()\n",
    "        self.preprocess_data()\n",
    "        self.train_and_evaluate()\n",
    "        \n",
    "        logger.info(\"Model building process completed.\")\n",
    "\n",
    "# Run the model building process\n",
    "if __name__ == \"__main__\":\n",
    "    base_directory = os.getcwd()\n",
    "    model_builder = ModelBuilder(base_directory)\n",
    "    model_builder.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
