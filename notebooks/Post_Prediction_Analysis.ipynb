{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 20:52:08,417 - INFO - Loading data from /mnt/c/Users/Nas/Contacts/Desktop/AIM/kaim-week-4/kaim-week-4/cleaned_data/primary_data.csv...\n",
      "2025-01-10 20:52:15,024 - INFO - Data loaded successfully!\n",
      "2025-01-10 20:52:15,025 - INFO - Preprocessing data...\n",
      "2025-01-10 20:52:16,287 - INFO - Data preprocessing completed.\n",
      "2025-01-10 20:52:16,290 - INFO - Training the model...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.utils import resample\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class PostPredictionAnalysis:\n",
    "    def __init__(self, data_path, loss_function='mse'):\n",
    "        \"\"\"\n",
    "        Initializes the PostPredictionAnalysis with the dataset and loss function.\n",
    "        \n",
    "        :param data_path: The path to the dataset.\n",
    "        :param loss_function: The loss function to use for model evaluation. Options are 'mse' or 'mae'.\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.df = None\n",
    "        self.model = None\n",
    "        self.loss_function = loss_function\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.feature_importances = None\n",
    "        self.predictions = None\n",
    "        self.confidence_intervals = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\" Loads the dataset. \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Loading data from {self.data_path}...\")\n",
    "            self.df = pd.read_csv(self.data_path)\n",
    "            logger.info(\"Data loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {e}\")\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\" Preprocess the data: handle missing values, encode categorical features, etc. \"\"\"\n",
    "        logger.info(\"Preprocessing data...\")\n",
    "        self.df.fillna(0, inplace=True)  # Simple imputation\n",
    "        X = self.df.drop(columns=['Sales', 'Date'])  # Features\n",
    "        y = self.df['Sales']  # Target\n",
    "        \n",
    "        # One-hot encoding for categorical variables\n",
    "        X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        logger.info(\"Data preprocessing completed.\")\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\" Train the regression model using Random Forest Regressor. \"\"\"\n",
    "        logger.info(\"Training the model...\")\n",
    "        self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        logger.info(\"Model trained successfully.\")\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        \"\"\" Evaluate the model using the selected loss function. \"\"\"\n",
    "        logger.info(f\"Evaluating the model using {self.loss_function}...\")\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        self.predictions = y_pred\n",
    "\n",
    "        if self.loss_function == 'mse':\n",
    "            loss = mean_squared_error(self.y_test, y_pred)\n",
    "            logger.info(f\"Mean Squared Error: {loss}\")\n",
    "        elif self.loss_function == 'mae':\n",
    "            loss = mean_absolute_error(self.y_test, y_pred)\n",
    "            logger.info(f\"Mean Absolute Error: {loss}\")\n",
    "        else:\n",
    "            logger.error(\"Invalid loss function. Use 'mse' or 'mae'.\")\n",
    "\n",
    "    def plot_feature_importance(self):\n",
    "        \"\"\" Plot feature importance from the trained model \"\"\"\n",
    "        logger.info(\"Plotting feature importance...\")\n",
    "        if self.model is not None:\n",
    "            self.feature_importances = self.model.feature_importances_\n",
    "            feature_importance_df = pd.DataFrame({\n",
    "                'Feature': self.df.drop(columns=['Sales', 'Date']).columns,\n",
    "                'Importance': self.feature_importances\n",
    "            })\n",
    "            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "            plt.xlabel('Importance')\n",
    "            plt.title('Feature Importance')\n",
    "            plt.show()\n",
    "        else:\n",
    "            logger.error(\"Model is not trained. Please train the model first.\")\n",
    "\n",
    "    def estimate_confidence_interval(self, n_bootstrap=1000, alpha=0.05):\n",
    "        \"\"\" Estimate confidence intervals for predictions using bootstrap sampling \"\"\"\n",
    "        logger.info(\"Estimating confidence intervals...\")\n",
    "        bootstrap_predictions = []\n",
    "        for _ in range(n_bootstrap):\n",
    "            X_resampled, y_resampled = resample(self.X_train, self.y_train, random_state=42)\n",
    "            self.model.fit(X_resampled, y_resampled)\n",
    "            bootstrap_predictions.append(self.model.predict(self.X_train))\n",
    "\n",
    "        # Calculate confidence intervals (lower and upper bounds)\n",
    "        bootstrap_predictions = np.array(bootstrap_predictions)\n",
    "        lower_bound = np.percentile(bootstrap_predictions, alpha/2 * 100, axis=0)\n",
    "        upper_bound = np.percentile(bootstrap_predictions, (1 - alpha/2) * 100, axis=0)\n",
    "\n",
    "        self.confidence_intervals = pd.DataFrame({\n",
    "            'Prediction': self.predictions,\n",
    "            'Lower Bound': lower_bound,\n",
    "            'Upper Bound': upper_bound\n",
    "        })\n",
    "        \n",
    "        logger.info(f\"Confidence intervals estimated at the {100*(1-alpha)}% confidence level.\")\n",
    "\n",
    "    def plot_confidence_intervals(self):\n",
    "        \"\"\" Plot the confidence intervals of the predictions \"\"\"\n",
    "        logger.info(\"Plotting confidence intervals...\")\n",
    "        if self.confidence_intervals is not None:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(self.confidence_intervals['Prediction'], label='Predictions', color='blue')\n",
    "            plt.fill_between(range(len(self.confidence_intervals)), \n",
    "                             self.confidence_intervals['Lower Bound'], \n",
    "                             self.confidence_intervals['Upper Bound'], \n",
    "                             color='gray', alpha=0.3, label='Confidence Interval')\n",
    "            plt.title('Predictions with Confidence Intervals')\n",
    "            plt.xlabel('Index')\n",
    "            plt.ylabel('Sales')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        else:\n",
    "            logger.error(\"Confidence intervals not estimated. Please run estimate_confidence_interval first.\")\n",
    "\n",
    "\n",
    "# Run the model pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = os.path.abspath(\"../cleaned_data/primary_data.csv\")  # Update with your path\n",
    "    model = PostPredictionAnalysis(data_path, loss_function='mse')  # You can choose 'mae' here as well\n",
    "\n",
    "    # Execute the model steps\n",
    "    model.load_data()\n",
    "    model.preprocess_data()\n",
    "    model.train_model()\n",
    "    model.evaluate_model()\n",
    "    model.plot_feature_importance()\n",
    "    model.estimate_confidence_interval()\n",
    "    model.plot_confidence_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
